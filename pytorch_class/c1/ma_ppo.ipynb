{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook utilisation de torch pour du MARL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import de la bibliotheque torchrl et de l'ensemble des pakage nécessaire a un systeme multi agent qui tourne sur GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FX643778\\AppData\\Local\\anaconda3\\envs\\pythorch_class\\lib\\site-packages\\torchrl\\data\\replay_buffers\\samplers.py:36: UserWarning: Failed to import torchrl C++ binaries. Some modules (eg, prioritized replay buffers) may not work with your installation. This is likely due to a discrepancy between your package version and the PyTorch version. Make sure both are compatible. Usually, torchrl majors follow the pytorch majors within a few days around the release. For instance, TorchRL 0.5 requires PyTorch 2.4.0, and TorchRL 0.6 requires PyTorch 2.5.0.\n",
      "  warnings.warn(EXTENSION_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Tensordict modules\n",
    "from tensordict.nn import set_composite_lp_aggregate, TensorDictModule\n",
    "from tensordict.nn.distributions import NormalParamExtractor\n",
    "from torch import multiprocessing\n",
    "\n",
    "# Data collection\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data.replay_buffers import ReplayBuffer\n",
    "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
    "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
    "\n",
    "# Env\n",
    "from torchrl.envs import RewardSum, TransformedEnv\n",
    "from torchrl.envs.libs.vmas import VmasEnv\n",
    "from torchrl.envs.utils import check_env_specs\n",
    "\n",
    "# Multi-agent network\n",
    "from torchrl.modules import MultiAgentMLP, ProbabilisticActor, TanhNormal\n",
    "\n",
    "# Loss\n",
    "from torchrl.objectives import ClipPPOLoss, ValueEstimators\n",
    "\n",
    "# Utils\n",
    "torch.manual_seed(0)\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selection des hyperparametre pour l'entrainement on commence par definie avec quoi sera entrainer le modele (cpu ou gpu) en fonction de ce qui est disponible sue la machine si le gpu est diponible on va préferer l'utilise car ca permet de grandement accelerer l'apprentisage. Ensuite on a l'echantilonage le nombre d'action par bath le nombre d'iteration. Les hyperparamétre general de l'entrainement et ce spécifique a la methode PPO utilisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "is_fork = multiprocessing.get_start_method() == \"fork\"\n",
    "device = (\n",
    "    torch.device(0)\n",
    "    if torch.cuda.is_available() and not is_fork\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "print(device)\n",
    "\n",
    "vmas_device = device\n",
    "\n",
    "# Sampling\n",
    "frames_per_batch = 6_000  # Number of team frames collected per training iteration\n",
    "n_iters = 10  # Number of sampling and training iterations\n",
    "total_frames = frames_per_batch * n_iters\n",
    "\n",
    "# Training\n",
    "num_epochs = 30  # Number of optimization steps per training iteration\n",
    "minibatch_size = 400  # Size of the mini-batches in each optimization step\n",
    "lr = 3e-4  # Learning rate\n",
    "max_grad_norm = 1.0  # Maximum norm for the gradients\n",
    "\n",
    "# PPO\n",
    "clip_epsilon = 0.2  # clip value for PPO loss\n",
    "gamma = 0.99  # discount factor\n",
    "lmbda = 0.9  # lambda for generalised advantage estimation\n",
    "entropy_eps = 1e-4  # coefficient of the entropy term in the PPO loss\n",
    "\n",
    "# disable log-prob aggregation\n",
    "set_composite_lp_aggregate(False).set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choix et parametrage de l'environement utiliser. Ici il s'agit de l'environement de navigation de Vmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "source": [
    "max_steps = 100  # Episode steps before done\n",
    "num_vmas_envs = (\n",
    "    frames_per_batch // max_steps\n",
    ")  # Number of vectorized envs. frames_per_batch should be divisible by this number\n",
    "scenario_name = \"navigation\"\n",
    "n_agents = 3\n",
    "\n",
    "env = VmasEnv(\n",
    "    scenario=scenario_name,\n",
    "    num_envs=num_vmas_envs,\n",
    "    continuous_actions=True,  # VMAS supports both continuous and discrete actions\n",
    "    max_steps=max_steps,\n",
    "    device=vmas_device,\n",
    "    # Scenario kwargs\n",
    "    n_agents=n_agents,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_spec: Composite(\n",
      "    agents: Composite(\n",
      "        action: BoundedContinuous(\n",
      "            shape=torch.Size([60, 3, 2]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([60, 3, 2]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([60, 3, 2]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([60, 3]),\n",
      "        data_cls=None),\n",
      "    device=cpu,\n",
      "    shape=torch.Size([60]),\n",
      "    data_cls=None)\n",
      "reward_spec: Composite(\n",
      "    agents: Composite(\n",
      "        reward: UnboundedContinuous(\n",
      "            shape=torch.Size([60, 3, 1]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([60, 3, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([60, 3, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([60, 3]),\n",
      "        data_cls=None),\n",
      "    device=cpu,\n",
      "    shape=torch.Size([60]),\n",
      "    data_cls=None)\n",
      "done_spec: Composite(\n",
      "    done: Categorical(\n",
      "        shape=torch.Size([60, 1]),\n",
      "        space=CategoricalBox(n=2),\n",
      "        device=cpu,\n",
      "        dtype=torch.bool,\n",
      "        domain=discrete),\n",
      "    terminated: Categorical(\n",
      "        shape=torch.Size([60, 1]),\n",
      "        space=CategoricalBox(n=2),\n",
      "        device=cpu,\n",
      "        dtype=torch.bool,\n",
      "        domain=discrete),\n",
      "    device=cpu,\n",
      "    shape=torch.Size([60]),\n",
      "    data_cls=None)\n",
      "observation_spec: Composite(\n",
      "    agents: Composite(\n",
      "        observation: UnboundedContinuous(\n",
      "            shape=torch.Size([60, 3, 18]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([60, 3, 18]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([60, 3, 18]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        info: Composite(\n",
      "            pos_rew: UnboundedContinuous(\n",
      "                shape=torch.Size([60, 3, 1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([60, 3, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([60, 3, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            final_rew: UnboundedContinuous(\n",
      "                shape=torch.Size([60, 3, 1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([60, 3, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([60, 3, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            agent_collisions: UnboundedContinuous(\n",
      "                shape=torch.Size([60, 3, 1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([60, 3, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([60, 3, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=cpu,\n",
      "            shape=torch.Size([60, 3]),\n",
      "            data_cls=None),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([60, 3]),\n",
      "        data_cls=None),\n",
      "    device=cpu,\n",
      "    shape=torch.Size([60]),\n",
      "    data_cls=None)\n"
     ]
    }
   ],
   "source": [
    "print(\"action_spec:\", env.full_action_spec)\n",
    "print(\"reward_spec:\", env.full_reward_spec)\n",
    "print(\"done_spec:\", env.full_done_spec)\n",
    "print(\"observation_spec:\", env.observation_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_keys: [('agents', 'action')]\n",
      "reward_keys: [('agents', 'reward')]\n",
      "done_keys: ['done', 'terminated']\n"
     ]
    }
   ],
   "source": [
    "print(\"action_keys:\", env.action_keys)\n",
    "print(\"reward_keys:\", env.reward_keys)\n",
    "print(\"done_keys:\", env.done_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajout d'une nouvelle sortie a l'environement. On somme les reward pour chaque agent au fils des iteration ca permet d'avoir un suivie des performence de l'agent a chaque étape de l'entrainement et donc pouvoir suivre si l'entrainement ce passe bien ou non."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TransformedEnv(\n",
    "    env,\n",
    "    RewardSum(in_keys=[env.reward_key], out_keys=[(\"agents\", \"episode_reward\")]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2025-07-31 13:17:45,704 [torchrl][INFO]\u001b[0m    check_env_specs succeeded!\u001b[92m [END]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "check_env_specs(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test pour voir la forme de la sortie dans une trajectoire complete (rollout). Ici la trajectoire fait 5 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rollout of three steps: TensorDict(\n",
      "    fields={\n",
      "        agents: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([60, 5, 3, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                episode_reward: Tensor(shape=torch.Size([60, 5, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                info: TensorDict(\n",
      "                    fields={\n",
      "                        agent_collisions: Tensor(shape=torch.Size([60, 5, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        final_rew: Tensor(shape=torch.Size([60, 5, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        pos_rew: Tensor(shape=torch.Size([60, 5, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([60, 5, 3]),\n",
      "                    device=cpu,\n",
      "                    is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([60, 5, 3, 18]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([60, 5, 3]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([60, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                agents: TensorDict(\n",
      "                    fields={\n",
      "                        episode_reward: Tensor(shape=torch.Size([60, 5, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        info: TensorDict(\n",
      "                            fields={\n",
      "                                agent_collisions: Tensor(shape=torch.Size([60, 5, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                                final_rew: Tensor(shape=torch.Size([60, 5, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                                pos_rew: Tensor(shape=torch.Size([60, 5, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                            batch_size=torch.Size([60, 5, 3]),\n",
      "                            device=cpu,\n",
      "                            is_shared=False),\n",
      "                        observation: Tensor(shape=torch.Size([60, 5, 3, 18]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        reward: Tensor(shape=torch.Size([60, 5, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([60, 5, 3]),\n",
      "                    device=cpu,\n",
      "                    is_shared=False),\n",
      "                done: Tensor(shape=torch.Size([60, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([60, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([60, 5]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([60, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([60, 5]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n",
      "Shape of the rollout TensorDict: torch.Size([60, 5])\n"
     ]
    }
   ],
   "source": [
    "n_rollout_steps = 5\n",
    "rollout = env.rollout(n_rollout_steps)\n",
    "print(\"rollout of three steps:\", rollout)\n",
    "print(\"Shape of the rollout TensorDict:\", rollout.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametrage du reseux utiliser pour l'apprentisage. On utilise le modele multi agent de torchrl et on configure les parametre d'apprentisage : nombre d'agent, décentraliser, une polituqye partager. Et la forme des sortie pour qu'elles s'adapte a notre modéle ici on utilise PPO donc pour chaque actionn il faut deux sorties une pour la moyenne et une pour l'écart type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_parameters_policy = True\n",
    "\n",
    "policy_net = torch.nn.Sequential(\n",
    "    MultiAgentMLP(\n",
    "        n_agent_inputs=env.observation_spec[\"agents\", \"observation\"].shape[\n",
    "            -1\n",
    "        ],  # n_obs_per_agent\n",
    "        n_agent_outputs=2\n",
    "        * env.full_action_spec[env.action_key].shape[-1],  # 2 * n_actions_per_agents\n",
    "        n_agents=env.n_agents,\n",
    "        centralised=False,  # the policies are decentralised (ie each agent will act from its observation)\n",
    "        share_params=share_parameters_policy,\n",
    "        device=device,\n",
    "        depth=2,\n",
    "        num_cells=256,\n",
    "        activation_class=torch.nn.Tanh,\n",
    "    ),\n",
    "    NormalParamExtractor(),  # this will just separate the last dimension into two outputs: a loc and a non-negative scale\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_module = TensorDictModule(\n",
    "    policy_net,\n",
    "    in_keys=[(\"agents\", \"observation\")],\n",
    "    out_keys=[(\"agents\", \"loc\"), (\"agents\", \"scale\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = ProbabilisticActor(\n",
    "    module=policy_module,\n",
    "    spec=env.action_spec_unbatched,\n",
    "    in_keys=[(\"agents\", \"loc\"), (\"agents\", \"scale\")],\n",
    "    out_keys=[env.action_key],\n",
    "    distribution_class=TanhNormal,\n",
    "    distribution_kwargs={\n",
    "        \"low\": env.full_action_spec_unbatched[env.action_key].space.low,\n",
    "        \"high\": env.full_action_spec_unbatched[env.action_key].space.high,\n",
    "    },\n",
    "    return_log_prob=True,\n",
    ")  # we'll need the log-prob for the PPO loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_parameters_critic = True\n",
    "mappo = True  # IPPO if False\n",
    "\n",
    "critic_net = MultiAgentMLP(\n",
    "    n_agent_inputs=env.observation_spec[\"agents\", \"observation\"].shape[-1],\n",
    "    n_agent_outputs=1,  # 1 value per agent\n",
    "    n_agents=env.n_agents,\n",
    "    centralised=mappo,\n",
    "    share_params=share_parameters_critic,\n",
    "    device=device,\n",
    "    depth=2,\n",
    "    num_cells=256,\n",
    "    activation_class=torch.nn.Tanh,\n",
    ")\n",
    "\n",
    "critic = TensorDictModule(\n",
    "    module=critic_net,\n",
    "    in_keys=[(\"agents\", \"observation\")],\n",
    "    out_keys=[(\"agents\", \"state_value\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running policy: TensorDict(\n",
      "    fields={\n",
      "        agents: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([60, 3, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                action_log_prob: Tensor(shape=torch.Size([60, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                episode_reward: Tensor(shape=torch.Size([60, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                info: TensorDict(\n",
      "                    fields={\n",
      "                        agent_collisions: Tensor(shape=torch.Size([60, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        final_rew: Tensor(shape=torch.Size([60, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        pos_rew: Tensor(shape=torch.Size([60, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([60, 3]),\n",
      "                    device=cpu,\n",
      "                    is_shared=False),\n",
      "                loc: Tensor(shape=torch.Size([60, 3, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([60, 3, 18]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                scale: Tensor(shape=torch.Size([60, 3, 2]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([60, 3]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([60, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([60, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([60]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n",
      "Running value: TensorDict(\n",
      "    fields={\n",
      "        agents: TensorDict(\n",
      "            fields={\n",
      "                episode_reward: Tensor(shape=torch.Size([60, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                info: TensorDict(\n",
      "                    fields={\n",
      "                        agent_collisions: Tensor(shape=torch.Size([60, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        final_rew: Tensor(shape=torch.Size([60, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        pos_rew: Tensor(shape=torch.Size([60, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([60, 3]),\n",
      "                    device=cpu,\n",
      "                    is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([60, 3, 18]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                state_value: Tensor(shape=torch.Size([60, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([60, 3]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([60, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([60, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([60]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "print(\"Running policy:\", policy(env.reset()))\n",
    "print(\"Running value:\", critic(env.reset()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SyncDataCollector est un object de data collector qui est la pour faire fonctioner l'environement avec la politique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = SyncDataCollector(\n",
    "    env,\n",
    "    policy,\n",
    "    device=vmas_device,\n",
    "    storing_device=device,\n",
    "    frames_per_batch=frames_per_batch,\n",
    "    total_frames=total_frames,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecte les résultats de chaque pas pour les stocker. Dans ce cas la ce n'est pas nécessaire car on utilise PPO une methode on policy, donc en theorie il n'est pas nécessaire de mémoriser les données. Mais pour que le systeme soit adaptable et qu'il soit facile de changer la politique utiliser on le met. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = ReplayBuffer(\n",
    "    storage=LazyTensorStorage(\n",
    "        frames_per_batch, device=device\n",
    "    ),  # We store the frames_per_batch collected at each iteration\n",
    "    sampler=SamplerWithoutReplacement(),\n",
    "    batch_size=minibatch_size,  # We will sample minibatches of this size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FX643778\\AppData\\Local\\anaconda3\\envs\\pythorch_class\\lib\\site-packages\\torchrl\\objectives\\ppo.py:450: DeprecationWarning: 'entropy_coef' is deprecated and will be removed in torchrl v0.11. Please use 'entropy_coeff' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loss_module = ClipPPOLoss(\n",
    "    actor_network=policy,\n",
    "    critic_network=critic,\n",
    "    clip_epsilon=clip_epsilon,\n",
    "    entropy_coef=entropy_eps,\n",
    "    normalize_advantage=False,  # Important to avoid normalizing across the agent dimension\n",
    ")\n",
    "loss_module.set_keys(  # We have to tell the loss where to find the keys\n",
    "    reward=env.reward_key,\n",
    "    action=env.action_key,\n",
    "    value=(\"agents\", \"state_value\"),\n",
    "    # These last 2 keys will be expanded to match the reward shape\n",
    "    done=(\"agents\", \"done\"),\n",
    "    terminated=(\"agents\", \"terminated\"),\n",
    ")\n",
    "\n",
    "\n",
    "loss_module.make_value_estimator(\n",
    "    ValueEstimators.GAE, gamma=gamma, lmbda=lmbda\n",
    ")  # We build GAE\n",
    "GAE = loss_module.value_estimator\n",
    "\n",
    "optim = torch.optim.Adam(loss_module.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode_reward_mean = 2.6582961082458496: 100%|██████████| 10/10 [01:04<00:00,  6.51s/it]"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(total=n_iters, desc=\"episode_reward_mean = 0\")\n",
    "\n",
    "episode_reward_mean_list = []\n",
    "for tensordict_data in collector:\n",
    "    tensordict_data.set(\n",
    "        (\"next\", \"agents\", \"done\"),\n",
    "        tensordict_data.get((\"next\", \"done\"))\n",
    "        .unsqueeze(-1)\n",
    "        .expand(tensordict_data.get_item_shape((\"next\", env.reward_key))),\n",
    "    )\n",
    "    tensordict_data.set(\n",
    "        (\"next\", \"agents\", \"terminated\"),\n",
    "        tensordict_data.get((\"next\", \"terminated\"))\n",
    "        .unsqueeze(-1)\n",
    "        .expand(tensordict_data.get_item_shape((\"next\", env.reward_key))),\n",
    "    )\n",
    "    # We need to expand the done and terminated to match the reward shape (this is expected by the value estimator)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        GAE(\n",
    "            tensordict_data,\n",
    "            params=loss_module.critic_network_params,\n",
    "            target_params=loss_module.target_critic_network_params,\n",
    "        )  # Compute GAE and add it to the data\n",
    "\n",
    "    data_view = tensordict_data.reshape(-1)  # Flatten the batch size to shuffle data\n",
    "    replay_buffer.extend(data_view)\n",
    "\n",
    "    for _ in range(num_epochs):\n",
    "        for _ in range(frames_per_batch // minibatch_size):\n",
    "            subdata = replay_buffer.sample()\n",
    "            loss_vals = loss_module(subdata)\n",
    "\n",
    "            loss_value = (\n",
    "                loss_vals[\"loss_objective\"]\n",
    "                + loss_vals[\"loss_critic\"]\n",
    "                + loss_vals[\"loss_entropy\"]\n",
    "            )\n",
    "\n",
    "            loss_value.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                loss_module.parameters(), max_grad_norm\n",
    "            )  # Optional\n",
    "\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "\n",
    "    collector.update_policy_weights_()\n",
    "\n",
    "    # Logging\n",
    "    done = tensordict_data.get((\"next\", \"agents\", \"done\"))\n",
    "    episode_reward_mean = (\n",
    "        tensordict_data.get((\"next\", \"agents\", \"episode_reward\"))[done].mean().item()\n",
    "    )\n",
    "    episode_reward_mean_list.append(episode_reward_mean)\n",
    "    pbar.set_description(f\"episode_reward_mean = {episode_reward_mean}\", refresh=False)\n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(episode_reward_mean_list)\n",
    "plt.xlabel(\"Training iterations\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Episode reward mean\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe noyau s’est bloqué lors de l’exécution du code dans une cellule active ou une cellule précédente. \n",
      "\u001b[1;31mVeuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. \n",
      "\u001b[1;31mCliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "   env.rollout(\n",
    "       max_steps=max_steps,\n",
    "       policy=policy,\n",
    "       callback=lambda env, _: env.render(),\n",
    "       auto_cast_to_device=True,\n",
    "       break_when_any_done=False,\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_0\n",
      "[0.3303232  0.8560711  0.9209376  0.8076919  0.04149616 0.7671225\n",
      " 0.48432627 0.55417025 0.0353204  0.99076504 0.35985306 0.11851893\n",
      " 0.2303184  0.01887183 0.42475572]\n",
      "agent_1\n",
      "[0.7246486  0.7414706  0.2710491  0.87474346 0.96436167 0.06890906\n",
      " 0.6603872  0.778328   0.8051682  0.23036987 0.17518213 0.4503157\n",
      " 0.58986205 0.5215824  0.61040336]\n",
      "agent_0\n",
      "[0.86785686 0.774882   0.37935263 0.7840806  0.2656097  0.8621521\n",
      " 0.74405    0.96014    0.7389489  0.5459471  0.05169765 0.9266583\n",
      " 0.9209105  0.9771934  0.11437654]\n",
      "agent_1\n",
      "[0.79867435 0.48655885 0.6848226  0.5103217  0.08158539 0.07465586\n",
      " 0.07767667 0.3797392  0.4227094  0.18284316 0.6648153  0.32719365\n",
      " 0.2578456  0.18097107 0.26102364]\n",
      "agent_0\n",
      "[0.7822236  0.4020435  0.17444259 0.46407205 0.47806123 0.44813964\n",
      " 0.6225739  0.76242423 0.18523292 0.6043167  0.7254495  0.72082794\n",
      " 0.04519903 0.31902945 0.6689128 ]\n",
      "agent_1\n",
      "[0.10468926 0.21690378 0.8923117  0.83373344 0.35957414 0.65644747\n",
      " 0.51015323 0.3576047  0.44649178 0.2776511  0.45518416 0.37635574\n",
      " 0.6625785  0.8754546  0.4127677 ]\n",
      "agent_0\n",
      "[0.27991018 0.9027834  0.13350235 0.7099346  0.83176965 0.64449865\n",
      " 0.34574035 0.8329652  0.15681198 0.7265403  0.39121085 0.7841992\n",
      " 0.6253787  0.42417836 0.7941114 ]\n",
      "agent_1\n",
      "[0.05967148 0.6871384  0.59528357 0.08849042 0.698951   0.04652612\n",
      " 0.42632198 0.79106444 0.78748316 0.4659018  0.49162856 0.22241285\n",
      " 0.3573302  0.47966617 0.6816037 ]\n",
      "agent_0\n",
      "[0.04625672 0.53940094 0.9362569  0.396972   0.00188476 0.75616753\n",
      " 0.7641151  0.50760883 0.82387793 0.44898906 0.8821607  0.24169108\n",
      " 0.7181564  0.2876462  0.60496664]\n",
      "agent_1\n",
      "[0.6866987  0.09885783 0.5780716  0.8998984  0.6329781  0.14572607\n",
      " 0.8421751  0.18188165 0.3488687  0.92887664 0.7349577  0.92480296\n",
      " 0.6034945  0.87646645 0.8873818 ]\n",
      "agent_0\n",
      "[0.858782   0.74550825 0.7653327  0.5651118  0.8589147  0.4965035\n",
      " 0.93524915 0.2161635  0.8009714  0.1227277  0.33307055 0.4989215\n",
      " 0.7038557  0.327505   0.08458223]\n",
      "agent_1\n",
      "[0.4264735  0.04823928 0.859058   0.4410719  0.9923449  0.5221728\n",
      " 0.1609238  0.9873907  0.42742336 0.85192937 0.7293318  0.8798139\n",
      " 0.15446062 0.7937287  0.39673814]\n",
      "agent_0\n",
      "[0.622583   0.12615377 0.25960463 0.56286526 0.25816035 0.5447887\n",
      " 0.6091326  0.4803007  0.43108994 0.17591661 0.8128943  0.99160683\n",
      " 0.47576255 0.6307331  0.252071  ]\n",
      "agent_1\n",
      "[0.8821291  0.41293004 0.22905251 0.47281232 0.91568214 0.2664465\n",
      " 0.35825756 0.02453578 0.03321337 0.51190567 0.40272373 0.83850473\n",
      " 0.83001894 0.5358495  0.17304339]\n",
      "agent_0\n",
      "[0.13868006 0.19900875 0.28436157 0.00528171 0.27578372 0.82216835\n",
      " 0.43619877 0.5505446  0.07473866 0.85278815 0.57488495 0.5640082\n",
      " 0.02841279 0.7988203  0.15483819]\n",
      "agent_1\n",
      "[0.13562445 0.20958033 0.33815694 0.815558   0.06914052 0.12416381\n",
      " 0.51478124 0.4525974  0.82328296 0.12445991 0.7178942  0.8207391\n",
      " 0.27029452 0.8241959  0.6578957 ]\n",
      "agent_0\n",
      "[0.7606829  0.19208811 0.6988607  0.6404164  0.6369909  0.7224992\n",
      " 0.7382323  0.01105113 0.39571676 0.27362165 0.02427548 0.86420757\n",
      " 0.96552116 0.4114618  0.7484763 ]\n",
      "agent_1\n",
      "[0.6673213  0.6684966  0.98009473 0.8420423  0.32602137 0.56845146\n",
      " 0.30776808 0.2220462  0.05466283 0.22268042 0.6421126  0.97715604\n",
      " 0.45145455 0.7235067  0.7677863 ]\n",
      "agent_0\n",
      "[0.51961416 0.77483517 0.36479193 0.8208918  0.65800214 0.88729\n",
      " 0.397953   0.6486622  0.78500825 0.6857135  0.6203783  0.42758864\n",
      " 0.621991   0.5737711  0.35338837]\n",
      "agent_1\n",
      "[0.60932904 0.24299222 0.58069193 0.56406987 0.12469688 0.6497593\n",
      " 0.5303785  0.5687446  0.31732878 0.3612584  0.7608043  0.10688936\n",
      " 0.99661833 0.19142668 0.31458583]\n",
      "agent_0\n",
      "[0.66709006 0.70070887 0.43610662 0.39640507 0.77888244 0.9920042\n",
      " 0.52964985 0.8762942  0.47684544 0.8835185  0.45512486 0.07122815\n",
      " 0.3127194  0.05760199 0.36655983]\n",
      "agent_1\n",
      "[0.06336634 0.34922788 0.09194326 0.6530744  0.20270962 0.13007158\n",
      " 0.08479302 0.24968824 0.3793904  0.04703379 0.09354173 0.37924945\n",
      " 0.6252856  0.9109859  0.3381017 ]\n",
      "agent_0\n",
      "[0.43461257 0.7617482  0.27189043 0.0286745  0.41073942 0.03543572\n",
      " 0.29331213 0.6231679  0.29983348 0.7930596  0.7767014  0.75556684\n",
      " 0.10595938 0.5641577  0.5125388 ]\n",
      "agent_1\n",
      "[0.17218184 0.06161433 0.33416605 0.9066088  0.30883324 0.7724773\n",
      " 0.6669237  0.03384162 0.8714871  0.89484686 0.28288698 0.71730757\n",
      " 0.07626505 0.49493608 0.20910424]\n",
      "agent_0\n",
      "[0.8473907  0.18301338 0.6749496  0.6130249  0.4767683  0.83258116\n",
      " 0.6773636  0.40025672 0.04142199 0.80854833 0.38343105 0.86489964\n",
      " 0.73317534 0.84994036 0.43079433]\n",
      "agent_1\n",
      "[0.21508358 0.38329506 0.88216364 0.9130469  0.6508143  0.25678173\n",
      " 0.9605641  0.7849852  0.43072003 0.9612676  0.25766945 0.09014515\n",
      " 0.22139892 0.5807178  0.6558258 ]\n",
      "agent_0\n",
      "[0.2896614  0.9185525  0.07678209 0.7590891  0.7939908  0.44698307\n",
      " 0.50283957 0.7970812  0.8171224  0.89337856 0.6348763  0.5408828\n",
      " 0.852704   0.98163676 0.79759717]\n",
      "agent_1\n",
      "[0.5218568  0.8516435  0.7199852  0.29923895 0.10901989 0.698253\n",
      " 0.09793861 0.22900936 0.27472976 0.67265147 0.04388724 0.5876935\n",
      " 0.4521454  0.306803   0.18794006]\n",
      "agent_0\n",
      "[0.60202366 0.7781948  0.2046539  0.27044514 0.48371747 0.49944332\n",
      " 0.5450409  0.13950387 0.3155739  0.70727295 0.96120614 0.50407815\n",
      " 0.7664184  0.49722478 0.32133204]\n",
      "agent_1\n",
      "[0.70824265 0.949088   0.2509682  0.22320776 0.70427704 0.968703\n",
      " 0.23119389 0.11665445 0.4449918  0.99877787 0.6458992  0.40861642\n",
      " 0.5208813  0.06090187 0.41154155]\n",
      "agent_0\n",
      "[0.545027   0.09224641 0.50775516 0.26406717 0.93405193 0.87088287\n",
      " 0.12719446 0.76447684 0.82995886 0.34327877 0.04591179 0.86365926\n",
      " 0.25911096 0.43299794 0.4494962 ]\n",
      "agent_1\n",
      "[0.8999636  0.86667573 0.57539177 0.3921794  0.9510361  0.09898987\n",
      " 0.1401771  0.15035921 0.49520385 0.7506603  0.7545466  0.78870773\n",
      " 0.5636724  0.40632015 0.40066805]\n",
      "agent_0\n",
      "[0.7172691  0.814475   0.2938533  0.7566494  0.6556756  0.50662374\n",
      " 0.27315068 0.20865886 0.44636652 0.7062064  0.8421521  0.24284264\n",
      " 0.02697361 0.13203792 0.7010959 ]\n",
      "agent_1\n",
      "[0.95185155 0.650792   0.68229413 0.24237587 0.41870016 0.81389964\n",
      " 0.87365896 0.614228   0.064201   0.35272613 0.2381203  0.83111393\n",
      " 0.5955587  0.7078294  0.0928647 ]\n",
      "agent_0\n",
      "[0.6701394  0.33100057 0.40376183 0.08673922 0.85590553 0.57282144\n",
      " 0.5660915  0.6590044  0.5140491  0.58460873 0.71266997 0.37549382\n",
      " 0.7889847  0.07441328 0.05220535]\n",
      "agent_1\n",
      "[0.7672867  0.23057206 0.93935114 0.538827   0.9606416  0.8558196\n",
      " 0.5706175  0.56987137 0.3242604  0.03713765 0.5963986  0.6179872\n",
      " 0.4065116  0.53484696 0.184809  ]\n",
      "agent_0\n",
      "[0.3893481  0.02845945 0.62555665 0.262778   0.04526017 0.9489221\n",
      " 0.7545206  0.75383127 0.9901015  0.9500817  0.9777051  0.17282976\n",
      " 0.3033737  0.66208833 0.4984835 ]\n",
      "agent_1\n",
      "[0.85450953 0.42576227 0.92040604 0.2321288  0.01743476 0.5592801\n",
      " 0.7581227  0.8634264  0.77102536 0.7594716  0.6451944  0.18882573\n",
      " 0.9451721  0.8320878  0.7639195 ]\n",
      "agent_0\n",
      "[0.90198743 0.6737827  0.6709193  0.31143683 0.84100604 0.4702465\n",
      " 0.26927733 0.9831485  0.05867743 0.09654909 0.7653763  0.7074827\n",
      " 0.6946759  0.6166176  0.3400336 ]\n",
      "agent_1\n",
      "[0.5692436  0.72053516 0.5165552  0.71529704 0.0556118  0.45291474\n",
      " 0.18069227 0.65840787 0.70025563 0.8181384  0.23098381 0.06482458\n",
      " 0.84438926 0.14009953 0.69978064]\n",
      "agent_0\n",
      "[0.8732615  0.29645768 0.01662476 0.91575825 0.6873961  0.6071704\n",
      " 0.5555857  0.19687182 0.8465008  0.05663974 0.51807135 0.7239065\n",
      " 0.67830634 0.12290344 0.9036275 ]\n",
      "agent_1\n",
      "[0.3424506  0.8420838  0.3784272  0.24384415 0.4887201  0.8150982\n",
      " 0.35423782 0.07937583 0.5377014  0.8716256  0.3800263  0.5761517\n",
      " 0.08014771 0.93723243 0.8484728 ]\n",
      "agent_0\n",
      "[0.8822657  0.55989873 0.10564398 0.6605498  0.05290955 0.59720635\n",
      " 0.01292693 0.32793263 0.37748078 0.76445264 0.79298645 0.43994725\n",
      " 0.83156264 0.5391485  0.33623797]\n",
      "agent_1\n",
      "[0.20778158 0.2921593  0.77299565 0.77687895 0.30398497 0.7404987\n",
      " 0.43202192 0.17609727 0.88149154 0.23080312 0.8707636  0.01066396\n",
      " 0.6539232  0.37551412 0.46657217]\n",
      "agent_0\n",
      "[0.9794701  0.76798993 0.832388   0.6250763  0.737045   0.8424053\n",
      " 0.3698059  0.57085854 0.49979365 0.365792   0.7162519  0.54701555\n",
      " 0.38985613 0.8619327  0.3103875 ]\n",
      "agent_1\n",
      "[0.01174673 0.18118419 0.01027725 0.11523814 0.8700786  0.27702203\n",
      " 0.9606528  0.9913395  0.9602289  0.06005032 0.01116542 0.7432906\n",
      " 0.76771    0.1805667  0.4826598 ]\n",
      "agent_0\n",
      "[0.745657   0.37116852 0.71953607 0.45108858 0.39057356 0.20091642\n",
      " 0.8968919  0.37372795 0.31531256 0.7060539  0.48989907 0.04721595\n",
      " 0.20860721 0.8860934  0.0968183 ]\n",
      "agent_1\n",
      "[0.2016763  0.00589052 0.5464984  0.81483364 0.12580512 0.58664435\n",
      " 0.6804646  0.6566411  0.6604695  0.85541576 0.46560204 0.01319108\n",
      " 0.23552795 0.42184284 0.28828844]\n",
      "agent_0\n",
      "[0.5760655  0.2789617  0.5585034  0.5287618  0.42731124 0.63463813\n",
      " 0.19237012 0.41052115 0.4728739  0.15429042 0.10605206 0.45640695\n",
      " 0.79485613 0.647962   0.6360268 ]\n",
      "agent_1\n",
      "[0.7230833  0.9338472  0.13169552 0.06215211 0.7370141  0.44851017\n",
      " 0.99403614 0.25976184 0.700612   0.78865016 0.94874626 0.41697246\n",
      " 0.8605199  0.82583207 0.8512393 ]\n",
      "agent_0\n",
      "agent_1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythorch_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
