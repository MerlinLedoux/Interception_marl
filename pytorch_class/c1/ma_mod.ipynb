{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook utilisation de torch pour du MARL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deuxime version du note book je vais jouer sur les hyperparametre l'utilisation d'autre modele, d'autre environement pour voir tous ce qu'il est possible de faire et comprendre comment l'adapter a mon cas.\n",
    "Import de la bibliotheque torchrl et de l'ensemble des pakage nécessaire a un systeme multi agent qui tourne sur GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FX643778\\AppData\\Local\\anaconda3\\envs\\pythorch_class\\lib\\site-packages\\torchrl\\data\\replay_buffers\\samplers.py:36: UserWarning: Failed to import torchrl C++ binaries. Some modules (eg, prioritized replay buffers) may not work with your installation. This is likely due to a discrepancy between your package version and the PyTorch version. Make sure both are compatible. Usually, torchrl majors follow the pytorch majors within a few days around the release. For instance, TorchRL 0.5 requires PyTorch 2.4.0, and TorchRL 0.6 requires PyTorch 2.5.0.\n",
      "  warnings.warn(EXTENSION_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Tensordict modules\n",
    "from tensordict.nn import set_composite_lp_aggregate, TensorDictModule\n",
    "from tensordict.nn.distributions import NormalParamExtractor\n",
    "from torch import multiprocessing\n",
    "\n",
    "# Data collection\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data.replay_buffers import ReplayBuffer\n",
    "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
    "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
    "\n",
    "# Env\n",
    "from torchrl.envs import RewardSum, TransformedEnv\n",
    "from torchrl.envs.libs.vmas import VmasEnv\n",
    "from torchrl.envs.utils import check_env_specs\n",
    "from torchrl.envs.libs.pettingzoo import PettingZooEnv\n",
    "\n",
    "# Multi-agent network\n",
    "from torchrl.modules import MultiAgentMLP, ProbabilisticActor, TanhNormal\n",
    "\n",
    "# Loss\n",
    "from torchrl.objectives import ClipPPOLoss, ValueEstimators\n",
    "\n",
    "# Utils\n",
    "torch.manual_seed(0)\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selection des hyperparametre pour l'entrainement on commence par definie avec quoi sera entrainer le modele (cpu ou gpu) en fonction de ce qui est disponible sue la machine si le gpu est diponible on va préferer l'utilise car ca permet de grandement accelerer l'apprentisage. Ensuite on a l'echantilonage le nombre d'action par bath le nombre d'iteration. Les hyperparamétre general de l'entrainement et ce spécifique a la methode PPO utilisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "is_fork = multiprocessing.get_start_method() == \"fork\"\n",
    "device = (\n",
    "    torch.device(0)\n",
    "    if torch.cuda.is_available() and not is_fork\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "print(device)\n",
    "\n",
    "vmas_device = device\n",
    "\n",
    "# Sampling\n",
    "frames_per_batch = 6_000  # Number of team frames collected per training iteration\n",
    "n_iters = 50  # Number of sampling and training iterations\n",
    "total_frames = frames_per_batch * n_iters\n",
    "\n",
    "# Training\n",
    "num_epochs = 30  # Number of optimization steps per training iteration\n",
    "minibatch_size = 400  # Size of the mini-batches in each optimization step\n",
    "lr = 3e-4  # Learning rate\n",
    "max_grad_norm = 1.0  # Maximum norm for the gradients\n",
    "\n",
    "# PPO\n",
    "clip_epsilon = 0.2  # clip value for PPO loss\n",
    "gamma = 0.99  # discount factor\n",
    "lmbda = 0.9  # lambda for generalised advantage estimation\n",
    "entropy_eps = 1e-4  # coefficient of the entropy term in the PPO loss\n",
    "\n",
    "# disable log-prob aggregation\n",
    "set_composite_lp_aggregate(False).set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choix et parametrage de l'environement utiliser. Ici il s'agit de l'environement de navigation de Vmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "source": [
    "max_steps = 1000  # Episode steps before done\n",
    "num_vmas_envs = (\n",
    "    frames_per_batch // max_steps\n",
    ")  # Number of vectorized envs. frames_per_batch should be divisible by this number\n",
    "scenario_name = \"balance\"\n",
    "n_agents = 2\n",
    "\n",
    "\n",
    "env = VmasEnv(\n",
    "    scenario=scenario_name,\n",
    "    num_envs=num_vmas_envs,\n",
    "    continuous_actions=True,  # VMAS supports both continuous and discrete actions\n",
    "    max_steps=max_steps,\n",
    "    device=vmas_device,\n",
    "    # Scenario kwargs\n",
    "    n_agents=n_agents,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_spec: Composite(\n",
      "    agents: Composite(\n",
      "        action: BoundedContinuous(\n",
      "            shape=torch.Size([6, 2, 2]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([6, 2, 2]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([6, 2, 2]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([6, 2]),\n",
      "        data_cls=None),\n",
      "    device=cpu,\n",
      "    shape=torch.Size([6]),\n",
      "    data_cls=None)\n",
      "reward_spec: Composite(\n",
      "    agents: Composite(\n",
      "        reward: UnboundedContinuous(\n",
      "            shape=torch.Size([6, 2, 1]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([6, 2, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([6, 2, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([6, 2]),\n",
      "        data_cls=None),\n",
      "    device=cpu,\n",
      "    shape=torch.Size([6]),\n",
      "    data_cls=None)\n",
      "done_spec: Composite(\n",
      "    done: Categorical(\n",
      "        shape=torch.Size([6, 1]),\n",
      "        space=CategoricalBox(n=2),\n",
      "        device=cpu,\n",
      "        dtype=torch.bool,\n",
      "        domain=discrete),\n",
      "    terminated: Categorical(\n",
      "        shape=torch.Size([6, 1]),\n",
      "        space=CategoricalBox(n=2),\n",
      "        device=cpu,\n",
      "        dtype=torch.bool,\n",
      "        domain=discrete),\n",
      "    device=cpu,\n",
      "    shape=torch.Size([6]),\n",
      "    data_cls=None)\n",
      "observation_spec: Composite(\n",
      "    agents: Composite(\n",
      "        observation: UnboundedContinuous(\n",
      "            shape=torch.Size([6, 2, 16]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([6, 2, 16]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([6, 2, 16]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        info: Composite(\n",
      "            pos_rew: UnboundedContinuous(\n",
      "                shape=torch.Size([6, 2, 1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([6, 2, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([6, 2, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            ground_rew: UnboundedContinuous(\n",
      "                shape=torch.Size([6, 2, 1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([6, 2, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([6, 2, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=cpu,\n",
      "            shape=torch.Size([6, 2]),\n",
      "            data_cls=None),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([6, 2]),\n",
      "        data_cls=None),\n",
      "    device=cpu,\n",
      "    shape=torch.Size([6]),\n",
      "    data_cls=None)\n"
     ]
    }
   ],
   "source": [
    "print(\"action_spec:\", env.full_action_spec)\n",
    "print(\"reward_spec:\", env.full_reward_spec)\n",
    "print(\"done_spec:\", env.full_done_spec)\n",
    "print(\"observation_spec:\", env.observation_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_keys: [('agents', 'action')]\n",
      "reward_keys: [('agents', 'reward')]\n",
      "done_keys: ['done', 'terminated']\n"
     ]
    }
   ],
   "source": [
    "print(\"action_keys:\", env.action_keys)\n",
    "print(\"reward_keys:\", env.reward_keys)\n",
    "print(\"done_keys:\", env.done_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajout d'une nouvelle sortie a l'environement. On somme les reward pour chaque agent au fils des iteration ca permet d'avoir un suivie des performence de l'agent a chaque étape de l'entrainement et donc pouvoir suivre si l'entrainement ce passe bien ou non."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TransformedEnv(\n",
    "    env,\n",
    "    RewardSum(in_keys=[env.reward_key], out_keys=[(\"agents\", \"episode_reward\")]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2025-07-31 13:59:11,159 [torchrl][INFO]\u001b[0m    check_env_specs succeeded!\u001b[92m [END]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "check_env_specs(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test pour voir la forme de la sortie dans une trajectoire complete (rollout). Ici la trajectoire fait 5 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rollout of three steps: TensorDict(\n",
      "    fields={\n",
      "        agents: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([6, 5, 2, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                episode_reward: Tensor(shape=torch.Size([6, 5, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                info: TensorDict(\n",
      "                    fields={\n",
      "                        ground_rew: Tensor(shape=torch.Size([6, 5, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        pos_rew: Tensor(shape=torch.Size([6, 5, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([6, 5, 2]),\n",
      "                    device=cpu,\n",
      "                    is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([6, 5, 2, 16]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([6, 5, 2]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([6, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                agents: TensorDict(\n",
      "                    fields={\n",
      "                        episode_reward: Tensor(shape=torch.Size([6, 5, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        info: TensorDict(\n",
      "                            fields={\n",
      "                                ground_rew: Tensor(shape=torch.Size([6, 5, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                                pos_rew: Tensor(shape=torch.Size([6, 5, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                            batch_size=torch.Size([6, 5, 2]),\n",
      "                            device=cpu,\n",
      "                            is_shared=False),\n",
      "                        observation: Tensor(shape=torch.Size([6, 5, 2, 16]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        reward: Tensor(shape=torch.Size([6, 5, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([6, 5, 2]),\n",
      "                    device=cpu,\n",
      "                    is_shared=False),\n",
      "                done: Tensor(shape=torch.Size([6, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([6, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([6, 5]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([6, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([6, 5]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n",
      "Shape of the rollout TensorDict: torch.Size([6, 5])\n"
     ]
    }
   ],
   "source": [
    "n_rollout_steps = 5\n",
    "rollout = env.rollout(n_rollout_steps)\n",
    "print(\"rollout of three steps:\", rollout)\n",
    "print(\"Shape of the rollout TensorDict:\", rollout.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametrage du reseux utiliser pour l'apprentisage. On utilise le modele multi agent de torchrl et on configure les parametre d'apprentisage : nombre d'agent, décentraliser, une polituqye partager. Et la forme des sortie pour qu'elles s'adapte a notre modéle ici on utilise PPO donc pour chaque actionn il faut deux sorties une pour la moyenne et une pour l'écart type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_parameters_policy = True\n",
    "\n",
    "policy_net = torch.nn.Sequential(\n",
    "    MultiAgentMLP(\n",
    "        n_agent_inputs=env.observation_spec[\"agents\", \"observation\"].shape[\n",
    "            -1\n",
    "        ],  # n_obs_per_agent\n",
    "        n_agent_outputs=2\n",
    "        * env.full_action_spec[env.action_key].shape[-1],  # 2 * n_actions_per_agents\n",
    "        # n_agents=env.n_agents,\n",
    "        n_agents=kwargs[\"n_pistons\"],\n",
    "        centralised=False,  # the policies are decentralised (ie each agent will act from its observation)\n",
    "        share_params=share_parameters_policy,\n",
    "        device=device,\n",
    "        depth=2,\n",
    "        num_cells=256,\n",
    "        activation_class=torch.nn.Tanh,\n",
    "    ),\n",
    "    NormalParamExtractor(),  # this will just separate the last dimension into two outputs: a loc and a non-negative scale\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_module = TensorDictModule(\n",
    "    policy_net,\n",
    "    in_keys=[(\"agents\", \"observation\")],\n",
    "    out_keys=[(\"agents\", \"loc\"), (\"agents\", \"scale\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = ProbabilisticActor(\n",
    "    module=policy_module,\n",
    "    spec=env.action_spec_unbatched,\n",
    "    in_keys=[(\"agents\", \"loc\"), (\"agents\", \"scale\")],\n",
    "    out_keys=[env.action_key],\n",
    "    distribution_class=TanhNormal,\n",
    "    distribution_kwargs={\n",
    "        \"low\": env.full_action_spec_unbatched[env.action_key].space.low,\n",
    "        \"high\": env.full_action_spec_unbatched[env.action_key].space.high,\n",
    "    },\n",
    "    return_log_prob=True,\n",
    ")  # we'll need the log-prob for the PPO loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_parameters_critic = True\n",
    "mappo = True  # IPPO if False\n",
    "\n",
    "critic_net = MultiAgentMLP(\n",
    "    n_agent_inputs=env.observation_spec[\"agents\", \"observation\"].shape[-1],\n",
    "    n_agent_outputs=1,  # 1 value per agent\n",
    "    # n_agents=env.n_agents,\n",
    "    n_agents=,\n",
    "    centralised=mappo,\n",
    "    share_params=share_parameters_critic,\n",
    "    device=device,\n",
    "    depth=2,\n",
    "    num_cells=256,\n",
    "    activation_class=torch.nn.Tanh,\n",
    ")\n",
    "\n",
    "critic = TensorDictModule(\n",
    "    module=critic_net,\n",
    "    in_keys=[(\"agents\", \"observation\")],\n",
    "    out_keys=[(\"agents\", \"state_value\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running policy: TensorDict(\n",
      "    fields={\n",
      "        agents: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([6, 2, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                action_log_prob: Tensor(shape=torch.Size([6, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                episode_reward: Tensor(shape=torch.Size([6, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                info: TensorDict(\n",
      "                    fields={\n",
      "                        ground_rew: Tensor(shape=torch.Size([6, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        pos_rew: Tensor(shape=torch.Size([6, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([6, 2]),\n",
      "                    device=cpu,\n",
      "                    is_shared=False),\n",
      "                loc: Tensor(shape=torch.Size([6, 2, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([6, 2, 16]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                scale: Tensor(shape=torch.Size([6, 2, 2]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([6, 2]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([6, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([6, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([6]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n",
      "Running value: TensorDict(\n",
      "    fields={\n",
      "        agents: TensorDict(\n",
      "            fields={\n",
      "                episode_reward: Tensor(shape=torch.Size([6, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                info: TensorDict(\n",
      "                    fields={\n",
      "                        ground_rew: Tensor(shape=torch.Size([6, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        pos_rew: Tensor(shape=torch.Size([6, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([6, 2]),\n",
      "                    device=cpu,\n",
      "                    is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([6, 2, 16]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                state_value: Tensor(shape=torch.Size([6, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([6, 2]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([6, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([6, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([6]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "print(\"Running policy:\", policy(env.reset()))\n",
    "print(\"Running value:\", critic(env.reset()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SyncDataCollector est un object de data collector qui est la pour faire fonctioner l'environement avec la politique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = SyncDataCollector(\n",
    "    env,\n",
    "    policy,\n",
    "    device=vmas_device,\n",
    "    storing_device=device,\n",
    "    frames_per_batch=frames_per_batch,\n",
    "    total_frames=total_frames,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecte les résultats de chaque pas pour les stocker. Dans ce cas la ce n'est pas nécessaire car on utilise PPO une methode on policy, donc en theorie il n'est pas nécessaire de mémoriser les données. Mais pour que le systeme soit adaptable et qu'il soit facile de changer la politique utiliser on le met. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = ReplayBuffer(\n",
    "    storage=LazyTensorStorage(\n",
    "        frames_per_batch, device=device\n",
    "    ),  # We store the frames_per_batch collected at each iteration\n",
    "    sampler=SamplerWithoutReplacement(),\n",
    "    batch_size=minibatch_size,  # We will sample minibatches of this size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FX643778\\AppData\\Local\\anaconda3\\envs\\pythorch_class\\lib\\site-packages\\torchrl\\objectives\\ppo.py:450: DeprecationWarning: 'entropy_coef' is deprecated and will be removed in torchrl v0.11. Please use 'entropy_coeff' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loss_module = ClipPPOLoss(\n",
    "    actor_network=policy,\n",
    "    critic_network=critic,\n",
    "    clip_epsilon=clip_epsilon,\n",
    "    entropy_coef=entropy_eps,\n",
    "    normalize_advantage=False,  # Important to avoid normalizing across the agent dimension\n",
    ")\n",
    "loss_module.set_keys(  # We have to tell the loss where to find the keys\n",
    "    reward=env.reward_key,\n",
    "    action=env.action_key,\n",
    "    value=(\"agents\", \"state_value\"),\n",
    "    # These last 2 keys will be expanded to match the reward shape\n",
    "    done=(\"agents\", \"done\"),\n",
    "    terminated=(\"agents\", \"terminated\"),\n",
    ")\n",
    "\n",
    "\n",
    "loss_module.make_value_estimator(\n",
    "    ValueEstimators.GAE, gamma=gamma, lmbda=lmbda\n",
    ")  # We build GAE\n",
    "GAE = loss_module.value_estimator\n",
    "\n",
    "optim = torch.optim.Adam(loss_module.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode_reward_mean = 100.9836196899414: 100%|██████████| 50/50 [12:35<00:00, 15.34s/it] "
     ]
    }
   ],
   "source": [
    "pbar = tqdm(total=n_iters, desc=\"episode_reward_mean = 0\")\n",
    "\n",
    "episode_reward_mean_list = []\n",
    "for tensordict_data in collector:\n",
    "    tensordict_data.set(\n",
    "        (\"next\", \"agents\", \"done\"),\n",
    "        tensordict_data.get((\"next\", \"done\"))\n",
    "        .unsqueeze(-1)\n",
    "        .expand(tensordict_data.get_item_shape((\"next\", env.reward_key))),\n",
    "    )\n",
    "    tensordict_data.set(\n",
    "        (\"next\", \"agents\", \"terminated\"),\n",
    "        tensordict_data.get((\"next\", \"terminated\"))\n",
    "        .unsqueeze(-1)\n",
    "        .expand(tensordict_data.get_item_shape((\"next\", env.reward_key))),\n",
    "    )\n",
    "    # We need to expand the done and terminated to match the reward shape (this is expected by the value estimator)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        GAE(\n",
    "            tensordict_data,\n",
    "            params=loss_module.critic_network_params,\n",
    "            target_params=loss_module.target_critic_network_params,\n",
    "        )  # Compute GAE and add it to the data\n",
    "\n",
    "    data_view = tensordict_data.reshape(-1)  # Flatten the batch size to shuffle data\n",
    "    replay_buffer.extend(data_view)\n",
    "\n",
    "    for _ in range(num_epochs):\n",
    "        for _ in range(frames_per_batch // minibatch_size):\n",
    "            subdata = replay_buffer.sample()\n",
    "            loss_vals = loss_module(subdata)\n",
    "\n",
    "            loss_value = (\n",
    "                loss_vals[\"loss_objective\"]\n",
    "                + loss_vals[\"loss_critic\"]\n",
    "                + loss_vals[\"loss_entropy\"]\n",
    "            )\n",
    "\n",
    "            loss_value.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                loss_module.parameters(), max_grad_norm\n",
    "            )  # Optional\n",
    "\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "\n",
    "    collector.update_policy_weights_()\n",
    "\n",
    "    # Logging\n",
    "    done = tensordict_data.get((\"next\", \"agents\", \"done\"))\n",
    "    episode_reward_mean = (\n",
    "        tensordict_data.get((\"next\", \"agents\", \"episode_reward\"))[done].mean().item()\n",
    "    )\n",
    "    episode_reward_mean_list.append(episode_reward_mean)\n",
    "    pbar.set_description(f\"episode_reward_mean = {episode_reward_mean}\", refresh=False)\n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(episode_reward_mean_list)\n",
    "plt.xlabel(\"Training iterations\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Episode reward mean\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        agents: TensorDict(\n",
       "            fields={\n",
       "                action: Tensor(shape=torch.Size([6, 1000, 2, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                action_log_prob: Tensor(shape=torch.Size([6, 1000, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                episode_reward: Tensor(shape=torch.Size([6, 1000, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                info: TensorDict(\n",
       "                    fields={\n",
       "                        ground_rew: Tensor(shape=torch.Size([6, 1000, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        pos_rew: Tensor(shape=torch.Size([6, 1000, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                    batch_size=torch.Size([6, 1000, 2]),\n",
       "                    device=cpu,\n",
       "                    is_shared=False),\n",
       "                loc: Tensor(shape=torch.Size([6, 1000, 2, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                observation: Tensor(shape=torch.Size([6, 1000, 2, 16]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                scale: Tensor(shape=torch.Size([6, 1000, 2, 2]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([6, 1000, 2]),\n",
       "            device=cpu,\n",
       "            is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([6, 1000, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        next: TensorDict(\n",
       "            fields={\n",
       "                agents: TensorDict(\n",
       "                    fields={\n",
       "                        episode_reward: Tensor(shape=torch.Size([6, 1000, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        info: TensorDict(\n",
       "                            fields={\n",
       "                                ground_rew: Tensor(shape=torch.Size([6, 1000, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                pos_rew: Tensor(shape=torch.Size([6, 1000, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                            batch_size=torch.Size([6, 1000, 2]),\n",
       "                            device=cpu,\n",
       "                            is_shared=False),\n",
       "                        observation: Tensor(shape=torch.Size([6, 1000, 2, 16]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        reward: Tensor(shape=torch.Size([6, 1000, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                    batch_size=torch.Size([6, 1000, 2]),\n",
       "                    device=cpu,\n",
       "                    is_shared=False),\n",
       "                done: Tensor(shape=torch.Size([6, 1000, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                terminated: Tensor(shape=torch.Size([6, 1000, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "            batch_size=torch.Size([6, 1000]),\n",
       "            device=cpu,\n",
       "            is_shared=False),\n",
       "        terminated: Tensor(shape=torch.Size([6, 1000, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "    batch_size=torch.Size([6, 1000]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe noyau s’est bloqué lors de l’exécution du code dans une cellule active ou une cellule précédente. \n",
      "\u001b[1;31mVeuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. \n",
      "\u001b[1;31mCliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "frame_count = 0\n",
    "max_rendered_frames = 1000\n",
    "\n",
    "def render_callback(env, _):\n",
    "    global frame_count\n",
    "    if frame_count < max_rendered_frames:\n",
    "        env.render()\n",
    "        frame_count += 1\n",
    "\n",
    "env.rollout(\n",
    "    max_steps=max_steps,\n",
    "    policy=policy,\n",
    "    callback=render_callback,\n",
    "    auto_cast_to_device=True,\n",
    "    break_when_any_done=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_0 -> action aléatoire : [0.23824263 0.49061593 0.2755846  0.8542123  0.8882865 ]\n",
      "agent_1 -> action aléatoire : [0.14897706 0.7427515  0.6990683  0.7407246  0.03634968]\n",
      "agent_2 -> action aléatoire : [0.89305794 0.4516947  0.55527115 0.04877529 0.7884043 ]\n",
      "agent_0 -> action aléatoire : [0.09523629 0.54154533 0.6897011  0.18387054 0.28986958]\n",
      "agent_1 -> action aléatoire : [0.5991937  0.7659306  0.01936371 0.35354733 0.282225  ]\n",
      "agent_2 -> action aléatoire : [0.770443   0.396678   0.3703459  0.39468762 0.24586804]\n",
      "agent_0 -> action aléatoire : [0.59473264 0.24170512 0.74438614 0.666603   0.6976572 ]\n",
      "agent_1 -> action aléatoire : [0.5171431  0.64193016 0.11293946 0.5451091  0.35189053]\n",
      "agent_2 -> action aléatoire : [0.9928223  0.81476974 0.90205145 0.4341866  0.4594253 ]\n",
      "agent_0 -> action aléatoire : [0.5779388  0.06964643 0.63765526 0.67694247 0.28368926]\n",
      "agent_1 -> action aléatoire : [0.31426358 0.92743313 0.4807602  0.66364884 0.34714282]\n",
      "agent_2 -> action aléatoire : [0.5335299  0.04992891 0.6240443  0.57077795 0.9206524 ]\n",
      "agent_0 -> action aléatoire : [0.40643317 0.04891945 0.21025771 0.5879345  0.13508876]\n",
      "agent_1 -> action aléatoire : [0.11987948 0.38143855 0.75536346 0.03687098 0.43113595]\n",
      "agent_2 -> action aléatoire : [0.17659636 0.5848448  0.23584309 0.1520442  0.8928466 ]\n",
      "agent_0 -> action aléatoire : [0.62489045 0.86763394 0.41811532 0.59007704 0.18759091]\n",
      "agent_1 -> action aléatoire : [0.04144876 0.8366601  0.227043   0.24960205 0.32845455]\n",
      "agent_2 -> action aléatoire : [0.7310319  0.98134243 0.41732144 0.8371487  0.9845686 ]\n",
      "agent_0 -> action aléatoire : [0.23026527 0.86820006 0.44404212 0.7249733  0.37852204]\n",
      "agent_1 -> action aléatoire : [0.0217831  0.21856977 0.20189226 0.7061403  0.9059227 ]\n",
      "agent_2 -> action aléatoire : [0.07032371 0.5805269  0.7371525  0.47002167 0.02242616]\n",
      "agent_0 -> action aléatoire : [0.4507798  0.6022961  0.37477008 0.19946678 0.08152518]\n",
      "agent_1 -> action aléatoire : [0.02081827 0.9614091  0.6896614  0.5230877  0.44791442]\n",
      "agent_2 -> action aléatoire : [0.13586253 0.6254284  0.4665318  0.473746   0.29570287]\n",
      "agent_0 -> action aléatoire : [0.4199477  0.4762436  0.35505378 0.02999647 0.81847644]\n",
      "agent_1 -> action aléatoire : [0.6093172  0.19143572 0.8875867  0.14485098 0.9213071 ]\n",
      "agent_2 -> action aléatoire : [0.2985521  0.90480345 0.06640694 0.13281342 0.98287266]\n",
      "agent_0 -> action aléatoire : [0.49566078 0.5460769  0.02510506 0.2342612  0.9231791 ]\n",
      "agent_1 -> action aléatoire : [0.12057696 0.5973418  0.9168354  0.37771234 0.7224059 ]\n",
      "agent_2 -> action aléatoire : [0.4679765  0.530785   0.83471704 0.3144687  0.15962851]\n",
      "agent_0 -> action aléatoire : [0.28684667 0.44428357 0.43765768 0.24504125 0.62580943]\n",
      "agent_1 -> action aléatoire : [0.23524763 0.05180186 0.10497545 0.45253783 0.05551175]\n",
      "agent_2 -> action aléatoire : [0.49458346 0.07748395 0.978773   0.31440994 0.18045124]\n",
      "agent_0 -> action aléatoire : [0.3086672  0.92015994 0.77488565 0.58158934 0.3883788 ]\n",
      "agent_1 -> action aléatoire : [0.12631442 0.6487031  0.84667885 0.2219774  0.04608429]\n",
      "agent_2 -> action aléatoire : [0.9786221  0.3178424  0.4804216  0.6318418  0.22036083]\n",
      "agent_0 -> action aléatoire : [0.37079683 0.63381463 0.5813542  0.00086945 0.00080991]\n",
      "agent_1 -> action aléatoire : [0.84784967 0.6432441  0.67515665 0.45085675 0.01417264]\n",
      "agent_2 -> action aléatoire : [0.28748092 0.8788532  0.97425056 0.1301596  0.40784246]\n",
      "agent_0 -> action aléatoire : [0.45028082 0.592791   0.7016962  0.04014555 0.9225335 ]\n",
      "agent_1 -> action aléatoire : [0.74789304 0.5055605  0.87078214 0.22281356 0.17630471]\n",
      "agent_2 -> action aléatoire : [0.85968    0.77897877 0.09303831 0.82138795 0.33184054]\n",
      "agent_0 -> action aléatoire : [0.9372435  0.2529605  0.23970155 0.57442194 0.3747753 ]\n",
      "agent_1 -> action aléatoire : [0.28266516 0.12226793 0.96094304 0.03879035 0.6512222 ]\n",
      "agent_2 -> action aléatoire : [0.34552115 0.30835447 0.94343996 0.16774504 0.20087682]\n",
      "agent_0 -> action aléatoire : [0.10532107 0.8042921  0.4052037  0.679657   0.8694277 ]\n",
      "agent_1 -> action aléatoire : [0.09373377 0.11191266 0.39432046 0.9684032  0.21665265]\n",
      "agent_2 -> action aléatoire : [0.19791985 0.9246868  0.8140648  0.572195   0.22047934]\n",
      "agent_0 -> action aléatoire : [0.8719016  0.09012836 0.3174027  0.2634607  0.8881775 ]\n",
      "agent_1 -> action aléatoire : [0.5124314  0.11253322 0.6053201  0.8793752  0.15101016]\n",
      "agent_2 -> action aléatoire : [0.62167525 0.89920336 0.5399677  0.9149025  0.33835423]\n",
      "agent_0 -> action aléatoire : [0.04473594 0.4336275  0.32565147 0.7225966  0.21635728]\n",
      "agent_1 -> action aléatoire : [0.760783   0.07894984 0.00512028 0.96184164 0.82284737]\n",
      "agent_2 -> action aléatoire : [0.6713586  0.5557087  0.8468757  0.23989896 0.5904449 ]\n",
      "agent_0 -> action aléatoire : [0.54038274 0.10030045 0.01830853 0.06862398 0.21900354]\n",
      "agent_1 -> action aléatoire : [0.7870793  0.90798867 0.4890546  0.94412524 0.04347851]\n",
      "agent_2 -> action aléatoire : [0.61072445 0.324588   0.3120348  0.08112454 0.23667298]\n",
      "agent_0 -> action aléatoire : [0.55214816 0.20591801 0.75662214 0.2541972  0.94812953]\n",
      "agent_1 -> action aléatoire : [0.33834782 0.8486798  0.51094824 0.13545486 0.5704945 ]\n",
      "agent_2 -> action aléatoire : [0.35870215 0.03731233 0.6972068  0.7687081  0.45131913]\n",
      "agent_0 -> action aléatoire : [0.9218042  0.93519217 0.11214577 0.48570666 0.1159061 ]\n",
      "agent_1 -> action aléatoire : [0.05032873 0.6055403  0.84803975 0.11117842 0.30881074]\n",
      "agent_2 -> action aléatoire : [0.79582584 0.25733584 0.07439663 0.7179644  0.3144464 ]\n",
      "agent_0 -> action aléatoire : [0.01967834 0.50845844 0.3390842  0.93188995 0.28387886]\n",
      "agent_1 -> action aléatoire : [0.60525095 0.80832404 0.8331283  0.2976284  0.8637405 ]\n",
      "agent_2 -> action aléatoire : [0.01883848 0.33154583 0.14327651 0.39839593 0.5737219 ]\n",
      "agent_0 -> action aléatoire : [0.43944642 0.204808   0.88624203 0.98335546 0.6109707 ]\n",
      "agent_1 -> action aléatoire : [0.9153749  0.35987124 0.37636653 0.96860635 0.429613  ]\n",
      "agent_2 -> action aléatoire : [0.8009038  0.68908256 0.22835852 0.37144458 0.8051454 ]\n",
      "agent_0 -> action aléatoire : [0.6168093  0.80399483 0.39423224 0.23126268 0.509428  ]\n",
      "agent_1 -> action aléatoire : [0.37490526 0.8722738  0.2897992  0.5176896  0.85558814]\n",
      "agent_2 -> action aléatoire : [0.88289165 0.53193814 0.2788745  0.4564099  0.2541828 ]\n",
      "agent_0 -> action aléatoire : [0.7044304  0.47726133 0.7328496  0.6270426  0.08220001]\n",
      "agent_1 -> action aléatoire : [0.01990571 0.09204454 0.75741935 0.25299817 0.22173676]\n",
      "agent_2 -> action aléatoire : [0.55105984 0.91888726 0.09841374 0.973899   0.7621421 ]\n",
      "Total reward (somme sur tous les agents, normalisée) : -21.032816057926816\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pettingzoo.mpe import simple_spread_v3\n",
    "\n",
    "env = simple_spread_v3.env(render_mode=\"human\", continuous_actions=True)\n",
    "env.reset()\n",
    "\n",
    "obs_vide = torch.zeros(18, dtype=torch.float32)\n",
    "obs_agent0 = obs_vide.clone()\n",
    "obs_agent1 = obs_vide.clone()\n",
    "obs_agent2 = obs_vide.clone()\n",
    "\n",
    "sum_reward = 0\n",
    "\n",
    "for agent in env.agent_iter():\n",
    "    env.render()\n",
    "    observation, reward, termination, truncation, info = env.last()\n",
    "    sum_reward += reward / 3  # Moyenne simple entre 3 agents\n",
    "\n",
    "    if termination or truncation:\n",
    "        action = None\n",
    "    else:\n",
    "        # Action aléatoire de l'agent actif\n",
    "        action = env.action_space(agent).sample()\n",
    "        \n",
    "\n",
    "        # Mise à jour des observations (facultatif ici, mais utile si tu veux les afficher)\n",
    "        obs = torch.tensor(observation, dtype=torch.float32)\n",
    "        if agent == \"agent_0\":\n",
    "            obs_agent0 = obs\n",
    "        elif agent == \"agent_1\":\n",
    "            obs_agent1 = obs\n",
    "        elif agent == \"agent_2\":\n",
    "            obs_agent2 = obs\n",
    "\n",
    "        print(f\"{agent} -> action aléatoire : {action}\")\n",
    "\n",
    "    env.step(action)\n",
    "\n",
    "env.close()\n",
    "print(\"Total reward (somme sur tous les agents, normalisée) :\", sum_reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythorch_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
